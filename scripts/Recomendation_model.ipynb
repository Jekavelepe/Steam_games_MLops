{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de recomendaciones ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip \n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games = pd.read_csv('../datasets/steam_games_worked.csv.gz')\n",
    "user_items = pd.read_csv('../datasets/user_items_worked.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos las columnas que vamos a usar para nuestra matriz de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf_steam_games = steam_games[['id', 'genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willc\\AppData\\Local\\Temp\\ipykernel_19976\\1724516128.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataf_steam_games['genres'] = dataf_steam_games['genres'].apply(lambda x: eval(x))\n"
     ]
    }
   ],
   "source": [
    "# Desglosar las listas en la columna 'genres'\n",
    "dataf_steam_games['genres'] = dataf_steam_games['genres'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las columnas dummies apartir de la columna genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer  \n",
    "# Crear una instancia de MultiLabelBinarizer y ajustarla a los géneros\n",
    "multilbz = MultiLabelBinarizer()\n",
    "dummies = pd.DataFrame(multilbz.fit_transform(dataf_steam_games['genres']), columns=multilbz.classes_, index=dataf_steam_games.index)\n",
    "\n",
    "# Combinar las dummies con el DataFrame original y eliminar duplicados en la columna title\n",
    "df_steam_games_dummies = pd.concat([dataf_steam_games.drop('genres', axis=1), dummies], axis=1)\n",
    "df_steam_games_dummies = df_steam_games_dummies.drop_duplicates(subset='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games_dummies.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_game_id_ti = steam_games[['id', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761140</td>\n",
       "      <td>Lost Summoner Kitty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>643980</td>\n",
       "      <td>Ironbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670290</td>\n",
       "      <td>Real Pool 3D - Poolians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767400</td>\n",
       "      <td>弹炸人2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>773570</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                    title\n",
       "0  761140      Lost Summoner Kitty\n",
       "1  643980                Ironbound\n",
       "2  670290  Real Pool 3D - Poolians\n",
       "3  767400                  弹炸人2222\n",
       "4  773570                      NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_game_id_ti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora exportamos los df como csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games_dummies.to_csv('../datasets/df_steam_games_dummies.csv.gz',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_game_id_ti.to_csv('../datasets/steam_games_id_title.csv.gz',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recomendacion_juego(id_producto:int):\n",
    "    '''Ingresando el id de producto, deberíamos recibir una lista con 5 juegos recomendados similares al ingresado.'''\n",
    "\n",
    "    if not isinstance(id_producto, int):\n",
    "        try:\n",
    "            id_producto = int(id_producto)\n",
    "        except ValueError:\n",
    "            return 'El Id debe ser un número entero'\n",
    "\n",
    "    df_steam_games_with_dummies = pd.read_csv('../datasets/df_steam_games_dummies.csv.gz')\n",
    "    steam_game_id_title = pd.read_csv('../datasets/steam_games_id_title.csv.gz')\n",
    "    #Verificamos si el id ingresado esta en la base de datos\n",
    "    if id_producto not in df_steam_games_with_dummies['id'].unique():\n",
    "        return \"ID no encontrado\"\n",
    "    #convertimos la columna id en index\n",
    "    df_steam_games_with_dummies.set_index('id', inplace=True)\n",
    "\n",
    "    # Obtener las características del juego dado su ID\n",
    "    juego_caracteristicas = df_steam_games_with_dummies.loc[id_producto].values.reshape(1, -1)\n",
    "\n",
    "    # Calcular la similitud del coseno entre el juego dado y todos los otros juegos\n",
    "    similarities = cosine_similarity(df_steam_games_with_dummies.values, juego_caracteristicas)\n",
    "\n",
    "    # Ordenar los juegos según su similitud y tomar los 6 juegos más similares (el primero es el mismo juego)\n",
    "    similar_juegos_indices = similarities.flatten().argsort()[-6:-1][::-1]\n",
    "\n",
    "    # Obtener los títulos de los juegos recomendados\n",
    "    recommended_juegos = steam_game_id_title.loc[similar_juegos_indices, 'title'].tolist()\n",
    "\n",
    "    return recommended_juegos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aurora Trail', 'Tactical Genius Online', 'Card Hunter', 'The Banner Saga: Factions - Pillage! Pack', 'The Banner Saga: Factions - Eternal Renown Boost']\n"
     ]
    }
   ],
   "source": [
    "recomendaciones = recomendacion_juego(643980)\n",
    "print(recomendaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews = pd.read_csv('../datasets/user_reviews_worked.csv.gz',usecols=['user_id','item_id','sentiment_analysis','recommend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "76561198108415635      10\n",
       "NanoPi                 10\n",
       "banksyyo               10\n",
       "snubbo                 10\n",
       "BuffinMutton           10\n",
       "                       ..\n",
       "554076033               1\n",
       "_maximus                1\n",
       "maxstupo                1\n",
       "maxy21                  1\n",
       "SkullainnLovesGoats     1\n",
       "Name: count, Length: 25458, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_reviews['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761140</td>\n",
       "      <td>[Action, Casual, Indie, Simulation, Strategy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>643980</td>\n",
       "      <td>[Free to Play, Indie, RPG, Strategy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670290</td>\n",
       "      <td>[Casual, Free to Play, Indie, Simulation, Sports]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767400</td>\n",
       "      <td>[Action, Adventure, Casual]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>773570</td>\n",
       "      <td>[Action, Indie, Casual, Sports]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             genres\n",
       "0  761140      [Action, Casual, Indie, Simulation, Strategy]\n",
       "1  643980               [Free to Play, Indie, RPG, Strategy]\n",
       "2  670290  [Casual, Free to Play, Indie, Simulation, Sports]\n",
       "3  767400                        [Action, Adventure, Casual]\n",
       "4  773570                    [Action, Indie, Casual, Sports]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf_steam_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "#elimino la columna user_id\n",
    "df_user_reviews['user_id_num'] = label_encoder.fit_transform(df_user_reviews['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews['rating'] = np.where(df_user_reviews['recommend'] == True,  # Si 'recommend' es True\n",
    "                                 np.where(df_user_reviews['sentiment_analysis'] == 2, 5,  # Si 'sentimiento' es positivo\n",
    "                                          np.where(df_user_reviews['sentiment_analysis'] == 1, 3,  # Si 'sentimiento' es neutro\n",
    "                                                   1)),  # Si 'sentimiento' es negativo cuando 'recommend' es True\n",
    "                                 np.where(df_user_reviews['sentiment_analysis'] == 2, 4,  # Si 'sentimiento' es positivo\n",
    "                                          np.where(df_user_reviews['sentiment_analysis'] == 1, 2,  # Si 'sentimiento' es neutro\n",
    "                                                   0)))  # Si 'sentimiento' es negativo cuando 'recommend' es False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews.to_csv('../datasets/user_review_rating.csv.gz',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Suponiendo que tienes un DataFrame llamado 'df_ratings' con las columnas 'user_id', 'item_id' y 'rating'\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_user_reviews[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor RMSE: 1.589934322171901\n",
      "Mejores parámetros: {'n_factors': 5, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Importar GridSearchCV\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los parámetros para la búsqueda de cuadrícula\n",
    "param_grid = {'n_factors': [5, 50, 100], 'n_epochs': [5, 10, 20], 'lr_all': [0.001, 0.002, 0.005], 'reg_all': [0.002, 0.02, 0.2]}\n",
    "\n",
    "# Crear un objeto GridSearchCV con SVD como modelo, RMSE como métrica a optimizar, validación cruzada de 3 pliegues y uso de todos los núcleos disponibles\n",
    "gs = GridSearchCV(algo_class=SVD, param_grid=param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Ejecutar la búsqueda de cuadrícula en los datos\n",
    "gs.fit(data)\n",
    "\n",
    "# Obtener los mejores resultados de la búsqueda\n",
    "best_rmse = gs.best_score['rmse']\n",
    "best_params = gs.best_params['rmse']\n",
    "\n",
    "print(f\"Mejor RMSE: {best_rmse}\")\n",
    "print(f\"Mejores parámetros: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5992172139550802"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una instancia del modelo SVD y entrenarlo con el conjunto de entrenamiento\n",
    "model = SVD(n_factors = 5, n_epochs = 20, lr_all = 0.005, reg_all = 0.2)\n",
    "model.fit(trainset)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Calcular la precisión de las predicciones\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/SVD_model.pkl', 'wb') as file: # Exporto mi modelo\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_usuario(id_usuario:str):\n",
    "    ''' Ingresando el id de un usuario, deberíamos recibir una lista con 5 juegos recomendados para dicho usuario.'''\n",
    "    #importamos los datasets\n",
    "    df_ratings = pd.read_csv('../datasets/user_review_rating.csv.gz')\n",
    "    steam_game_id_title = pd.read_csv('../datasets/steam_games_id_title.csv.gz')\n",
    "\n",
    "    with open('../datasets/SVD_model.pkl', 'rb') as archivo:\n",
    "        model = pickle.load(archivo)\n",
    "\n",
    "    #Verificamos si el usuario esta en la base de datos\n",
    "    if id_usuario not in df_ratings['user_id'].unique():\n",
    "        return \"ID no encontrado\"\n",
    "    \n",
    "    # Obtener todos los juegos disponibles\n",
    "    todos_los_juegos = df_ratings['item_id'].unique()\n",
    "\n",
    "    # Obtener los juegos valorados por el usuario\n",
    "    juegos_valorados_por_usuario = df_ratings[df_ratings['user_id'] == id_usuario]['item_id'].unique()\n",
    "\n",
    "    # Obtener los juegos no valorados por el usuario\n",
    "    juegos_no_valorados = list(set(todos_los_juegos) - set(juegos_valorados_por_usuario))\n",
    "\n",
    "    # Crear un DataFrame con los juegos no valorados por el usuario\n",
    "    df_juegos_no_valorados = pd.DataFrame(juegos_no_valorados, columns=['item_id'])\n",
    "\n",
    "    # Hacer predicciones para los juegos no valorados por el usuario\n",
    "    df_juegos_no_valorados['prediccion'] = df_juegos_no_valorados['item_id'].apply(lambda x: model.predict(id_usuario, x).est)\n",
    "\n",
    "    # Ordenar los juegos por la calificación predicha y tomar los primeros n juegos como recomendación\n",
    "    juegos_recomendados = df_juegos_no_valorados.sort_values(by='prediccion', ascending=False)['item_id'].tolist()\n",
    "\n",
    "    # Obtener los títulos de los juegos recomendados que existen en steam_game_id_title\n",
    "    recommended_juegos = []\n",
    "    for juego_id in juegos_recomendados:\n",
    "       juego_titulo = steam_game_id_title.loc[steam_game_id_title['id'] == juego_id, 'title'].tolist()\n",
    "       if juego_titulo:\n",
    "            recommended_juegos.append(juego_titulo[0])\n",
    "            if len(recommended_juegos) == 5:\n",
    "                break\n",
    "\n",
    "    return recommended_juegos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rogue Legacy', 'Bastion', 'FEZ', 'Mass Effect', 'Halo: Spartan Assault']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion_usuario('snubbo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyect-env",
   "language": "python",
   "name": "proyect-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
